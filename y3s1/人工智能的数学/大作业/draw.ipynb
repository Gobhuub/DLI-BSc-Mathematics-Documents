{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.],\n",
      "        [6., 7., 8.]]), \n",
      "shape: (3, 3)\n",
      "---\n",
      "Kernal: tensor([[[[0., 1.],\n",
      "          [2., 3.]]]], grad_fn=<AliasBackward0>), \n",
      "shape: (2, 2)\n",
      "---\n",
      "Output: tensor([[ 0.,  3.,  8.,  4.],\n",
      "        [ 9., 19., 25., 10.],\n",
      "        [21., 37., 43., 16.],\n",
      "        [ 6.,  7.,  8.,  0.]], grad_fn=<ReshapeAliasBackward0>), \n",
      "shape: (4, 4)\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "# 为了方便起见，我们定义了一个计算卷积层的函数。\n",
    "# 此函数初始化卷积层权重，并对输入和输出提高和缩减相应的维数\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # 这里的（1，1）表示批量大小和通道数都是1\n",
    "    X = X.reshape((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    # 省略前两个维度：批量大小和通道\n",
    "    return Y.reshape(Y.shape[2:])\n",
    "\n",
    "# 请注意，这里每边都填充了1行或1列，因此总共添加了2行或2列\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=2, padding=1, bias=False)\n",
    "conv2d.weight = nn.Parameter(torch.Tensor([range(4)]).view((1, 1, 2, 2)))\n",
    "X = torch.Tensor([range(9)]).view((3, 3))\n",
    "Y = comp_conv2d(conv2d, X)\n",
    "print(f\"Input: {X}, \\nshape: {tuple(X.shape)}\\n---\")\n",
    "print(f\"Kernal: {torch.Tensor(conv2d.weight)}, \\nshape: {tuple(conv2d.weight[0][0].shape)}\\n---\")\n",
    "print(f\"Output: {Y}, \\nshape: {tuple(Y.shape)}\\n---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([[[0., 1., 2.],\n",
      "         [3., 4., 5.],\n",
      "         [6., 7., 8.]],\n",
      "\n",
      "        [[1., 2., 3.],\n",
      "         [4., 5., 6.],\n",
      "         [7., 8., 9.]]]), \n",
      "shape: (2, 3, 3)\n",
      "---\n",
      "Kernal: tensor([[[0., 1.],\n",
      "         [2., 3.]],\n",
      "\n",
      "        [[1., 2.],\n",
      "         [3., 4.]]]), \n",
      "shape: (2, 2, 2)\n",
      "---\n",
      "Output: tensor([[ 56.,  72.],\n",
      "        [104., 120.]]), \n",
      "shape: (2, 2)\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def corr2d(X, K):\n",
    "    \"\"\"Compute 2D cross-correlation.\n",
    "\n",
    "    Defined in :numref:`sec_conv_layer`\"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()\n",
    "    return Y\n",
    "\n",
    "def corr2d_multi_in(X, K):\n",
    "    # 先遍历“X”和“K”的第0个维度（通道维度），再把它们加在一起\n",
    "    return sum(corr2d(x, k) for x, k in zip(X, K))\n",
    "\n",
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
    "\n",
    "Y = corr2d_multi_in(X, K)\n",
    "print(f\"Input: {X}, \\nshape: {tuple(X.shape)}\\n---\")\n",
    "print(f\"Kernal: {K}, \\nshape: {tuple(K.shape)}\\n---\")\n",
    "print(f\"Output: {Y}, \\nshape: {tuple(Y.shape)}\\n---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([[[0., 1., 2.],\n",
      "         [3., 4., 5.],\n",
      "         [6., 7., 8.]],\n",
      "\n",
      "        [[1., 2., 3.],\n",
      "         [4., 5., 6.],\n",
      "         [7., 8., 9.]]]), \n",
      "shape: (2, 3, 3)\n",
      "---\n",
      "Kernal: tensor([[[[0., 1.],\n",
      "          [2., 3.]],\n",
      "\n",
      "         [[1., 2.],\n",
      "          [3., 4.]]],\n",
      "\n",
      "\n",
      "        [[[1., 2.],\n",
      "          [3., 4.]],\n",
      "\n",
      "         [[2., 3.],\n",
      "          [4., 5.]]],\n",
      "\n",
      "\n",
      "        [[[2., 3.],\n",
      "          [4., 5.]],\n",
      "\n",
      "         [[3., 4.],\n",
      "          [5., 6.]]]]), \n",
      "shape: (3, 2, 2, 2)\n",
      "---\n",
      "Output: tensor([[[ 56.,  72.],\n",
      "         [104., 120.]],\n",
      "\n",
      "        [[ 76., 100.],\n",
      "         [148., 172.]],\n",
      "\n",
      "        [[ 96., 128.],\n",
      "         [192., 224.]]]), \n",
      "shape: (3, 2, 2)\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    # 迭代“K”的第0个维度，每次都对输入“X”执行互相关运算。\n",
    "    # 最后将所有结果都叠加在一起\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)\n",
    "\n",
    "K = torch.stack((K, K + 1, K + 2), 0)\n",
    "Y = corr2d_multi_in_out(X, K)\n",
    "\n",
    "print(f\"Input: {X}, \\nshape: {tuple(X.shape)}\\n---\")\n",
    "print(f\"Kernal: {K}, \\nshape: {tuple(K.shape)}\\n---\")\n",
    "print(f\"Output: {Y}, \\nshape: {tuple(Y.shape)}\\n---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "num",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov  4 2022, 13:42:51) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eab8c0194dde8383dfcf93e7bc5839da199071925589d554bc5a3cd09c779e68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
